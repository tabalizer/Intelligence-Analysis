# üõ°Ô∏è Bayesian Cheat Sheet for Conventional Intelligence (Do-This Guide)

**Use when:** You must decide under uncertainty (e.g., issue warning, increase collection, brief leadership) from mixed-source reporting.

---

## 0) What model fits my question? (picker)
- **Binary judgment (credible/not; presence/absence)** ‚Üí **Beta‚ÄìBinomial**
- **Event **counts** per period (incidents/week, sightings/day)** ‚Üí **Poisson** (use **Negative Binomial** if counts are ‚Äúbursty‚Äù)
- **Magnitude (continuous) with many observations** ‚Üí **Normal** (only if needed; most intel use-cases are binary or counts)

---

## 1) Six-step workflow (follow in order)
1) **Define action** you might take (watch, warn, escalate) and its **cost**.
2) **Pick model** from the picker above.
3) **Set a prior from baseline** (see ¬ß2).
4) **Update with today‚Äôs data** (see ¬ß3).
5) **Decide with a rule** tied to action cost (see ¬ß4).
6) **Record a short note** (template in ¬ß6) and **monitor**.

---

## 2) How to set a prior from intel baselines (simple & defensible)

### A) For binary judgments (Beta prior for a true rate `p`)
- Use historical ‚Äúcredible fraction‚Äù for similar claims/sources:
  - Baseline rate `m` (0‚Äì1) and **prior strength** `s` (‚Äúequivalent past cases‚Äù you trust)
  - Prior: **Beta(Œ±, Œ≤)** with `Œ± = m*s`, `Œ≤ = (1‚àím)*s`
  - Typical `s`: **20** (light), **100** (moderate), **300** (strong history)

**Heuristic from Admiralty Code (adjust to your policy):**
- Source Reliability **A/B/C/D** ‚Üí pick `s = 150/100/60/30`
- Information Credibility **1/2/3/4/5/6** ‚Üí pick `m = 0.8/0.65/0.5/0.35/0.2/0.1`

> Example: B2 ‚Üí `m=0.65`, `s=100` ‚áí prior `Beta(65,35)`

### B) For counts (Gamma prior on rate `Œª` for Poisson)
- Baseline mean incidents per period `Œª0`, and prior strength `s` (‚Äúequivalent periods‚Äù)
- Prior: **Gamma(Œ±, Œ≤)** with `Œ± = Œª0*s`, `Œ≤ = s` (mean stays `Œª0`)
- **Overdispersion check:** from recent data compute mean `Œº` and variance `v`
  - If `v/Œº ‚â§ ~1.5` ‚Üí Poisson OK; **else use Negative Binomial** (NB) in ¬ß3C

---

## 3) Update rules (the ‚Äúmath‚Äù you actually use)

### A) Beta‚ÄìBinomial (binary credibility, success/fail)
- Observe `k` credible out of `n` checks
- **Posterior:** `Beta(Œ± + k, Œ≤ + n ‚àí k)`
- Report: posterior mean of `p` and **90% interval**

### B) Poisson via Gamma‚ÄìPoisson (incident counts)
- Observe `x` events over exposure `t` periods (often `t=1`)
- **Posterior on rate Œª:** `Gamma(Œ± + x, Œ≤ + t)`
- **Posterior predictive** for next period gives `P(next count ‚â• threshold)`

### C) Negative Binomial (counts with extra variance; ‚Äúbursty‚Äù)
- Use NB parameterized by **mean** `Œº` and **alpha** (overdispersion):
  - `Var = Œº + Œº¬≤/alpha` (smaller alpha ‚áí more bursty)
- Practical: start with `alpha ‚âà 1` if unsure; fit/tune as data accrue
- Decision uses **posterior predictive** like Poisson, but with NB

---

## 4) Decision rules tied to action cost (pick 1 and stick to it)

### Probability threshold (binary judgments)
- **Low-cost** actions (watchlist, targeted collection): act if `P(p > œÑ) > 0.7` (e.g., `œÑ = 0.3‚Äì0.5`)
- **Medium-cost** (stakeholder note/limited warning): `> 0.8`
- **High-cost/regulated** (public warning/resource shift): `‚â• 0.9`

### Spike rule (counts)
- Set a threshold (e.g., **2√ó** baseline next period)
- Act if `P(next count ‚â• threshold) > 0.7` (low cost), `> 0.8` (medium), `‚â• 0.9` (high)

### Expected Value (EV) sanity check (optional but good)
- `EV = (Probability of adverse outcome) √ó (Impact) ‚àí (Action cost)`
- If **EV > 0**, action is justified; pair with a probability rule above for stability

---

## 5) Worked micro-examples (plug and go)

### Example 1 ‚Äî HUMINT claim credibility (Beta‚ÄìBinomial)
- Source B2 ‚áí `m=0.65`, `s=100` ‚Üí prior `Beta(65,35)`
- Today: `k=6` credible corroborations out of `n=12` checks
- Posterior: `Beta(71,41)` ‚Üí compute `P(p > 0.5)`
- If `P > 0.9` and action is medium-cost ‚áí **issue stakeholder note**

### Example 2 ‚Äî Protest activity spike (counts)
- Baseline 4 incidents/day, choose `s=10` ‚Üí prior `Gamma(40,10)`
- Today `x=9` (t=1) ‚Üí posterior `Gamma(49,11)`
- Posterior predictive: `P(next day ‚â• 8) = 0.76` ‚áí **shift collection/watch** (0.7 rule)

### Example 3 ‚Äî Choosing between two narratives (A vs B) by corroboration rate
- Both start `Beta(1,1)`
- A: `k=12/30` ‚Üí `Beta(13,19)`; B: `k=18/35` ‚Üí `Beta(19,18)`
- Compute `P(p_B > p_A)`; if `> 0.9` and medium-cost action ‚áí **brief B as more likely**

---

## 6) Analyst note template (paste & fill)
- **Decision:** _(what you did)_
- **Rule:** _(e.g., P>0.8 spike rule; or EV>0)_
- **Model:** _(Beta‚ÄìBinomial / Poisson / NB)_
- **Prior:** `m=__`, `s=__` ‚Üí Beta(Œ±,Œ≤) **or** `Œª0=__`, `s=__` ‚Üí Gamma(Œ±,Œ≤)
- **Data:** `k=__/n=__` **or** `x=__` over `t=__`
- **Posterior key metric:** `point [low, high]`
- **Probability used:** `P(p>œÑ)=__` **or** `P(next‚â•threshold)=__`
- **Rationale (1‚Äì2 lines):** _why sufficient for action_
- **Monitoring:** _what & when you re-check_

---

## 7) ACH plug-in (optional but simple)
- Treat each hypothesis as an ‚Äúarm.‚Äù Score each new evidence item **E** with a **Likelihood Ratio (LR)** scale:
  - Strongly favors H: **LR 5**
  - Moderately favors H: **LR 3**
  - Slightly favors H: **LR 1.5**
  - Neutral: **LR 1**
  - Slightly against H: **LR 1/1.5**
  - Moderately against H: **LR 1/3**
  - Strongly against H: **LR 1/5**
- Start from prior odds (can be equal). **Posterior odds = prior odds √ó LR‚ÇÅ √ó LR‚ÇÇ √ó ‚Ä¶**
- Normalize to get posterior probabilities; apply the same **probability/EV rules** as above.

---

## 8) Pitfalls & fixes
- **Bursty counts using Poisson** ‚Üí switch to **Negative Binomial**
- **Unrealistic priors** ‚Üí do a quick **prior predictive** sanity check; re-center/widen
- **Tiny samples flipping decisions** ‚Üí keep prior strength modest (20‚Äì100) and require higher probability thresholds for high-cost actions
- **Moving thresholds** ‚Üí set thresholds **by policy & action cost** up front; don‚Äôt change them mid-stream

---

## 9) What to deliver up-chain (one slide/paragraph)
- The **decision** and the **rule** that triggered it
- The **probability** (or predictive spike chance) and a **90% interval**
- A brief **EV** note if stakes are high
- **Next check-in** (24‚Äì72h) and what will change the decision

---

**Provenance:** Standard Bayesian operational practice and structured analytic techniques (ACH, 5W1H).
